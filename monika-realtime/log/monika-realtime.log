2016-07-07 09:37:56 [com.superh.hz.monika.realtime.constant.MonikaConfiguration :29-line]-[INFO:] MONITOR_TASK_FLAG is [2]
2016-07-07 09:37:56 [com.superh.hz.monika.realtime.constant.MonikaConfiguration :32-line]-[INFO:] MONIKA_MONITOR_TASK_CLASS is []
2016-07-07 09:37:56 [com.superh.hz.monika.realtime.constant.MonikaConfiguration :35-line]-[INFO:] MONIKA_MONITOR_TASK_PARSER_CLASS is [null]
2016-07-07 09:37:56 [org.apache.hadoop.util.Shell :396-line]-[ERROR:] Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:130)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:94)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:74)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:303)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:790)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:760)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:633)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2160)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2160)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2160)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:874)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:81)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:140)
	at com.superh.hz.monika.realtime.job.MonitorJobStartup.buildReceiveStream(MonitorJobStartup.java:263)
	at com.superh.hz.monika.realtime.job.MonitorJobStartup.main(MonitorJobStartup.java:69)
2016-07-07 09:37:57 [akka.event.slf4j.Slf4jLogger :80-line]-[INFO:] Slf4jLogger started
2016-07-07 09:37:57 [Remoting :74-line]-[INFO:] Starting remoting
2016-07-07 09:37:57 [Remoting :74-line]-[INFO:] Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.16.4.109:55006]
2016-07-07 09:37:57 [org.spark-project.jetty.server.Server :272-line]-[INFO:] jetty-8.y.z-SNAPSHOT
2016-07-07 09:37:57 [org.spark-project.jetty.server.AbstractConnector :338-line]-[INFO:] Started SelectChannelConnector@0.0.0.0:4040
2016-07-07 09:37:59 [ :389-line]-[WARN:] Your hostname, huangchao resolves to a loopback/non-reachable address: fe80:0:0:0:e926:ee9c:e036:a320%eth5, but we couldn't find any external IP address!
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/api,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/static,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-07-07 09:38:07 [org.spark-project.jetty.server.handler.ContextHandler :843-line]-[INFO:] stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-07-07 09:38:37 [com.superh.hz.monika.realtime.constant.MonikaConfiguration :29-line]-[INFO:] MONITOR_TASK_FLAG is [2]
2016-07-07 09:38:37 [com.superh.hz.monika.realtime.constant.MonikaConfiguration :32-line]-[INFO:] MONIKA_MONITOR_TASK_CLASS is []
2016-07-07 09:38:37 [com.superh.hz.monika.realtime.constant.MonikaConfiguration :35-line]-[INFO:] MONIKA_MONITOR_TASK_PARSER_CLASS is [null]
2016-07-07 09:38:38 [org.apache.hadoop.util.Shell :396-line]-[ERROR:] Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:130)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:94)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:74)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:303)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:790)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:760)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:633)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2160)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2160)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2160)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:874)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:81)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:140)
	at com.superh.hz.monika.realtime.job.MonitorJobStartup.buildReceiveStream(MonitorJobStartup.java:263)
	at com.superh.hz.monika.realtime.job.MonitorJobStartup.main(MonitorJobStartup.java:69)
2016-07-07 09:38:38 [akka.event.slf4j.Slf4jLogger :80-line]-[INFO:] Slf4jLogger started
2016-07-07 09:38:38 [Remoting :74-line]-[INFO:] Starting remoting
2016-07-07 09:38:38 [Remoting :74-line]-[INFO:] Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.16.4.109:55099]
2016-07-07 09:38:39 [org.spark-project.jetty.server.Server :272-line]-[INFO:] jetty-8.y.z-SNAPSHOT
2016-07-07 09:38:39 [org.spark-project.jetty.server.AbstractConnector :338-line]-[INFO:] Started SelectChannelConnector@0.0.0.0:4040
2016-07-07 09:38:40 [ :389-line]-[WARN:] Your hostname, huangchao resolves to a loopback/non-reachable address: fe80:0:0:0:e926:ee9c:e036:a320%eth5, but we couldn't find any external IP address!
2016-07-07 09:38:42 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Recovered 1 write ahead log files from hdfs://mycluster/user/hadoop/hc/checkpoint/receivedBlockMetadata
2016-07-07 09:38:42 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Recovered 1 write ahead log files from hdfs://mycluster/user/hadoop/hc/checkpoint/receivedData/0
2016-07-07 09:38:42 [org.apache.spark.streaming.scheduler.ReceiverTracker :74-line]-[ERROR:] Deregistered receiver for stream 0: Error starting receiver 0 - java.lang.NullPointerException
	at java.util.Hashtable.put(Hashtable.java:459)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:154)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver.onStart(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:148)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:130)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:575)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:565)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2016-07-07 09:38:44 [org.apache.spark.streaming.receiver.ReceiverSupervisorImpl :74-line]-[ERROR:] Stopped receiver with error: java.lang.NullPointerException
2016-07-07 09:38:44 [org.apache.spark.executor.Executor :95-line]-[ERROR:] Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.NullPointerException
	at java.util.Hashtable.put(Hashtable.java:459)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:154)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver.onStart(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:148)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:130)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:575)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:565)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-07 09:38:44 [org.apache.spark.scheduler.TaskSetManager :74-line]-[ERROR:] Task 0 in stage 0.0 failed 1 times; aborting job
2016-07-07 09:38:44 [org.apache.spark.streaming.scheduler.ReceiverTracker :95-line]-[ERROR:] Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.NullPointerException
	at java.util.Hashtable.put(Hashtable.java:459)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:154)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver.onStart(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:148)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:130)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:575)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:565)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
Caused by: java.lang.NullPointerException
	at java.util.Hashtable.put(Hashtable.java:459)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:154)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver.onStart(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:148)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:130)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:575)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:565)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-07 09:38:44 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Recovered 1 write ahead log files from hdfs://mycluster/user/hadoop/hc/checkpoint/receivedData/0
2016-07-07 09:38:44 [org.apache.spark.streaming.scheduler.ReceiverTracker :74-line]-[ERROR:] Deregistered receiver for stream 0: Error starting receiver 0 - java.lang.NullPointerException
	at java.util.Hashtable.put(Hashtable.java:459)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:154)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver.onStart(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:148)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:130)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:575)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:565)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2016-07-07 09:38:44 [com.superh.hz.monika.realtime.job.MonitorJobStartup :292-line]-[INFO:] -----------------------------------------
2016-07-07 09:38:44 [com.superh.hz.monika.realtime.job.MonitorJobStartup :293-line]-[INFO:] Time: [1467855524339]ms
2016-07-07 09:38:44 [com.superh.hz.monika.realtime.job.MonitorJobStartup :294-line]-[INFO:] -----------------------------------------
2016-07-07 09:38:44 [com.superh.hz.monika.realtime.job.MonitorJobStartup :301-line]-[INFO:] 当前布控任务总数量：[0]
2016-07-07 09:38:44 [com.superh.hz.monika.realtime.job.MonitorJobStartup :356-line]-[INFO:] -------deal time=>[1467855524390],batch count：[0]
2016-07-07 09:38:44 [com.superh.hz.monika.realtime.job.MonitorJobStartup :357-line]-[INFO:] -------deal time=>[1467855524390],result count：[0]
2016-07-07 09:38:44 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 1 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint/receivedBlockMetadata older than 1467855520000: hdfs://mycluster/user/hadoop/hc/checkpoint/receivedBlockMetadata/log-1467171996015-1467172056015
2016-07-07 09:38:44 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Cleared log files in hdfs://mycluster/user/hadoop/hc/checkpoint/receivedBlockMetadata older than 1467855520000
2016-07-07 09:38:44 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 1 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint/receivedData/0 older than 1467855520000: hdfs://mycluster/user/hadoop/hc/checkpoint/receivedData/0/log-1467172006005-1467172066005
2016-07-07 09:38:44 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Cleared log files in hdfs://mycluster/user/hadoop/hc/checkpoint/receivedData/0 older than 1467855520000
2016-07-07 09:38:46 [org.apache.spark.streaming.receiver.ReceiverSupervisorImpl :74-line]-[ERROR:] Stopped receiver with error: java.lang.NullPointerException
2016-07-07 09:38:46 [org.apache.spark.executor.Executor :95-line]-[ERROR:] Exception in task 0.0 in stage 1.0 (TID 1)
java.lang.NullPointerException
	at java.util.Hashtable.put(Hashtable.java:459)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:154)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver.onStart(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:148)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:130)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:575)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:565)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-07 09:38:46 [org.apache.spark.scheduler.TaskSetManager :74-line]-[ERROR:] Task 0 in stage 1.0 failed 1 times; aborting job
2016-07-07 09:38:46 [org.apache.spark.streaming.scheduler.ReceiverTracker :95-line]-[ERROR:] Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1, localhost): java.lang.NullPointerException
	at java.util.Hashtable.put(Hashtable.java:459)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:154)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver.onStart(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:148)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:130)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:575)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:565)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
Caused by: java.lang.NullPointerException
	at java.util.Hashtable.put(Hashtable.java:459)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:154)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver.onStart(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:148)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:130)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:575)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:565)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-07 09:38:46 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Recovered 0 write ahead log files from hdfs://mycluster/user/hadoop/hc/checkpoint/receivedData/0
2016-07-07 09:38:46 [org.apache.spark.streaming.scheduler.ReceiverTracker :74-line]-[ERROR:] Deregistered receiver for stream 0: Error starting receiver 0 - java.lang.NullPointerException
	at java.util.Hashtable.put(Hashtable.java:459)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:154)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver.onStart(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:148)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:130)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:575)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:565)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2016-07-07 09:39:41 [com.superh.hz.monika.realtime.constant.MonikaConfiguration :29-line]-[INFO:] MONITOR_TASK_FLAG is [2]
2016-07-07 09:39:41 [com.superh.hz.monika.realtime.constant.MonikaConfiguration :32-line]-[INFO:] MONIKA_MONITOR_TASK_CLASS is []
2016-07-07 09:39:41 [com.superh.hz.monika.realtime.constant.MonikaConfiguration :35-line]-[INFO:] MONIKA_MONITOR_TASK_PARSER_CLASS is [null]
2016-07-07 09:39:41 [org.apache.hadoop.util.Shell :396-line]-[ERROR:] Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:130)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:94)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:74)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:303)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:790)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:760)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:633)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2160)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2160)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2160)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:874)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:81)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:140)
	at com.superh.hz.monika.realtime.job.MonitorJobStartup.buildReceiveStream(MonitorJobStartup.java:263)
	at com.superh.hz.monika.realtime.job.MonitorJobStartup.main(MonitorJobStartup.java:69)
2016-07-07 09:39:42 [akka.event.slf4j.Slf4jLogger :80-line]-[INFO:] Slf4jLogger started
2016-07-07 09:39:42 [Remoting :74-line]-[INFO:] Starting remoting
2016-07-07 09:39:42 [Remoting :74-line]-[INFO:] Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.16.4.109:55198]
2016-07-07 09:39:42 [org.spark-project.jetty.server.Server :272-line]-[INFO:] jetty-8.y.z-SNAPSHOT
2016-07-07 09:39:42 [org.spark-project.jetty.server.AbstractConnector :338-line]-[INFO:] Started SelectChannelConnector@0.0.0.0:4040
2016-07-07 09:39:44 [ :389-line]-[WARN:] Your hostname, huangchao resolves to a loopback/non-reachable address: fe80:0:0:0:e926:ee9c:e036:a320%eth5, but we couldn't find any external IP address!
2016-07-07 09:39:46 [org.apache.spark.streaming.scheduler.ReceiverTracker :74-line]-[ERROR:] Deregistered receiver for stream 0: Error starting receiver 0 - java.lang.NullPointerException
	at java.util.Hashtable.put(Hashtable.java:459)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:154)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver.onStart(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:148)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:130)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:575)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:565)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2016-07-07 09:39:48 [org.apache.spark.streaming.receiver.ReceiverSupervisorImpl :74-line]-[ERROR:] Stopped receiver with error: java.lang.NullPointerException
2016-07-07 09:39:48 [org.apache.spark.executor.Executor :95-line]-[ERROR:] Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.NullPointerException
	at java.util.Hashtable.put(Hashtable.java:459)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:154)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver.onStart(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:148)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:130)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:575)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:565)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-07 09:39:48 [org.apache.spark.scheduler.TaskSetManager :74-line]-[ERROR:] Task 0 in stage 0.0 failed 1 times; aborting job
2016-07-07 09:39:48 [org.apache.spark.streaming.scheduler.ReceiverTracker :95-line]-[ERROR:] Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.NullPointerException
	at java.util.Hashtable.put(Hashtable.java:459)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:154)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver.onStart(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:148)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:130)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:575)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:565)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
Caused by: java.lang.NullPointerException
	at java.util.Hashtable.put(Hashtable.java:459)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:154)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver.onStart(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:148)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:130)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:575)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:565)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-07 09:39:48 [org.apache.spark.streaming.scheduler.ReceiverTracker :74-line]-[ERROR:] Deregistered receiver for stream 0: Error starting receiver 0 - java.lang.NullPointerException
	at java.util.Hashtable.put(Hashtable.java:459)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:154)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver.onStart(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:148)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:130)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:575)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:565)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2016-07-07 09:39:48 [com.superh.hz.monika.realtime.job.MonitorJobStartup :292-line]-[INFO:] -----------------------------------------
2016-07-07 09:39:48 [com.superh.hz.monika.realtime.job.MonitorJobStartup :293-line]-[INFO:] Time: [1467855588289]ms
2016-07-07 09:39:48 [com.superh.hz.monika.realtime.job.MonitorJobStartup :294-line]-[INFO:] -----------------------------------------
2016-07-07 09:39:48 [com.superh.hz.monika.realtime.job.MonitorJobStartup :301-line]-[INFO:] 当前布控任务总数量：[0]
2016-07-07 09:39:48 [com.superh.hz.monika.realtime.job.MonitorJobStartup :356-line]-[INFO:] -------deal time=>[1467855588336],batch count：[0]
2016-07-07 09:39:48 [com.superh.hz.monika.realtime.job.MonitorJobStartup :357-line]-[INFO:] -------deal time=>[1467855588336],result count：[0]
2016-07-07 09:39:48 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855584000: 
2016-07-07 09:39:48 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855584000: 
2016-07-07 09:39:50 [org.apache.spark.streaming.receiver.ReceiverSupervisorImpl :74-line]-[ERROR:] Stopped receiver with error: java.lang.NullPointerException
2016-07-07 09:39:50 [org.apache.spark.executor.Executor :95-line]-[ERROR:] Exception in task 0.0 in stage 1.0 (TID 1)
java.lang.NullPointerException
	at java.util.Hashtable.put(Hashtable.java:459)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:154)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver.onStart(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:148)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:130)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:575)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:565)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-07 09:39:50 [org.apache.spark.scheduler.TaskSetManager :74-line]-[ERROR:] Task 0 in stage 1.0 failed 1 times; aborting job
2016-07-07 09:39:50 [org.apache.spark.streaming.scheduler.ReceiverTracker :95-line]-[ERROR:] Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1, localhost): java.lang.NullPointerException
	at java.util.Hashtable.put(Hashtable.java:459)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:154)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver.onStart(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:148)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:130)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:575)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:565)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
Caused by: java.lang.NullPointerException
	at java.util.Hashtable.put(Hashtable.java:459)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:154)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver.onStart(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:148)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:130)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:575)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:565)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-07 09:39:50 [org.apache.spark.streaming.scheduler.ReceiverTracker :74-line]-[ERROR:] Deregistered receiver for stream 0: Error starting receiver 0 - java.lang.NullPointerException
	at java.util.Hashtable.put(Hashtable.java:459)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver$$anonfun$onStart$3.apply(ReliableKafkaReceiver.scala:107)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:154)
	at org.apache.spark.streaming.kafka.ReliableKafkaReceiver.onStart(ReliableKafkaReceiver.scala:107)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:148)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:130)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:575)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:565)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:1992)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2016-07-07 09:43:21 [com.superh.hz.monika.realtime.constant.MonikaConfiguration :29-line]-[INFO:] MONITOR_TASK_FLAG is [2]
2016-07-07 09:43:21 [com.superh.hz.monika.realtime.constant.MonikaConfiguration :32-line]-[INFO:] MONIKA_MONITOR_TASK_CLASS is []
2016-07-07 09:43:21 [com.superh.hz.monika.realtime.constant.MonikaConfiguration :35-line]-[INFO:] MONIKA_MONITOR_TASK_PARSER_CLASS is [null]
2016-07-07 09:43:22 [org.apache.hadoop.util.Shell :396-line]-[ERROR:] Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:130)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:94)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:74)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:303)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:790)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:760)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:633)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2160)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2160)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2160)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:874)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:81)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:140)
	at com.superh.hz.monika.realtime.job.MonitorJobStartup.buildReceiveStream(MonitorJobStartup.java:263)
	at com.superh.hz.monika.realtime.job.MonitorJobStartup.main(MonitorJobStartup.java:69)
2016-07-07 09:43:22 [akka.event.slf4j.Slf4jLogger :80-line]-[INFO:] Slf4jLogger started
2016-07-07 09:43:22 [Remoting :74-line]-[INFO:] Starting remoting
2016-07-07 09:43:22 [Remoting :74-line]-[INFO:] Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.16.4.109:55309]
2016-07-07 09:43:23 [org.spark-project.jetty.server.Server :272-line]-[INFO:] jetty-8.y.z-SNAPSHOT
2016-07-07 09:43:23 [org.spark-project.jetty.server.AbstractConnector :338-line]-[INFO:] Started SelectChannelConnector@0.0.0.0:4040
2016-07-07 09:43:25 [ :389-line]-[WARN:] Your hostname, huangchao resolves to a loopback/non-reachable address: fe80:0:0:0:e926:ee9c:e036:a320%eth5, but we couldn't find any external IP address!
2016-07-07 09:43:26 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Recovered 1 write ahead log files from hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata
2016-07-07 09:43:26 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Verifying properties
2016-07-07 09:43:26 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property auto.commit.enable is overridden to false
2016-07-07 09:43:26 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property auto.offset.reset is overridden to smallest
2016-07-07 09:43:26 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property group.id is overridden to test_consumer_group_hctest
2016-07-07 09:43:26 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property zookeeper.connect is overridden to node1,node2,node3
2016-07-07 09:43:26 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b], Connecting to zookeeper instance at node1,node2,node3
2016-07-07 09:43:26 [org.I0Itec.zkclient.ZkEventThread :64-line]-[INFO:] Starting ZkClient event thread.
2016-07-07 09:43:26 [org.I0Itec.zkclient.ZkClient :449-line]-[INFO:] zookeeper state changed (SyncConnected)
2016-07-07 09:43:26 [org.I0Itec.zkclient.ZkEventThread :64-line]-[INFO:] Starting ZkClient event thread.
2016-07-07 09:43:26 [org.I0Itec.zkclient.ZkClient :449-line]-[INFO:] zookeeper state changed (SyncConnected)
2016-07-07 09:43:27 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b], begin registering consumer test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b in ZK
2016-07-07 09:43:27 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b], end registering consumer test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b in ZK
2016-07-07 09:43:27 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b], starting watcher executor thread for consumer test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b
2016-07-07 09:43:27 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b], begin rebalancing consumer test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b try #0
2016-07-07 09:43:27 [kafka.consumer.ConsumerFetcherManager :68-line]-[INFO:] [ConsumerFetcherManager-1467855806936] Stopping leader finder thread
2016-07-07 09:43:27 [kafka.consumer.ConsumerFetcherManager :68-line]-[INFO:] [ConsumerFetcherManager-1467855806936] Stopping all fetchers
2016-07-07 09:43:27 [kafka.consumer.ConsumerFetcherManager :68-line]-[INFO:] [ConsumerFetcherManager-1467855806936] All connections stopped
2016-07-07 09:43:27 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b], Cleared all relevant queues for this fetcher
2016-07-07 09:43:27 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b], Cleared the data chunks in all the consumer message iterators
2016-07-07 09:43:27 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b], Committing all offsets after clearing the fetcher queues
2016-07-07 09:43:27 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b], Releasing partition ownership
2016-07-07 09:43:27 [kafka.consumer.RangeAssignor :68-line]-[INFO:] Consumer test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b rebalancing the following partitions: ArrayBuffer(0, 1, 2, 3) for topic hctest with consumers: List(test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b-0)
2016-07-07 09:43:27 [kafka.consumer.RangeAssignor :68-line]-[INFO:] test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b-0 attempting to claim partition 0
2016-07-07 09:43:27 [kafka.consumer.RangeAssignor :68-line]-[INFO:] test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b-0 attempting to claim partition 1
2016-07-07 09:43:27 [kafka.consumer.RangeAssignor :68-line]-[INFO:] test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b-0 attempting to claim partition 2
2016-07-07 09:43:27 [kafka.consumer.RangeAssignor :68-line]-[INFO:] test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b-0 attempting to claim partition 3
2016-07-07 09:43:27 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b], test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b-0 successfully owned partition 0 for topic hctest
2016-07-07 09:43:27 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b], test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b-0 successfully owned partition 1 for topic hctest
2016-07-07 09:43:27 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b], test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b-0 successfully owned partition 2 for topic hctest
2016-07-07 09:43:27 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b], test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b-0 successfully owned partition 3 for topic hctest
2016-07-07 09:43:27 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b], Consumer test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b selected partitions : hctest:0: fetched offset = -1: consumed offset = -1,hctest:1: fetched offset = -1: consumed offset = -1,hctest:2: fetched offset = -1: consumed offset = -1,hctest:3: fetched offset = -1: consumed offset = -1
2016-07-07 09:43:27 [kafka.consumer.ConsumerFetcherManager$LeaderFinderThread :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b-leader-finder-thread], Starting 
2016-07-07 09:43:27 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b], end rebalancing consumer test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b try #0
2016-07-07 09:43:27 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Verifying properties
2016-07-07 09:43:27 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property client.id is overridden to test_consumer_group_hctest
2016-07-07 09:43:27 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property metadata.broker.list is overridden to node1:9092,node2:9092,node3:9092,node4:9092
2016-07-07 09:43:27 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property request.timeout.ms is overridden to 30000
2016-07-07 09:43:27 [kafka.client.ClientUtils$ :68-line]-[INFO:] Fetching metadata from broker id:1,host:node2,port:9092 with correlation id 0 for 1 topic(s) Set(hctest)
2016-07-07 09:43:27 [kafka.producer.SyncProducer :68-line]-[INFO:] Connected to node2:9092 for producing
2016-07-07 09:43:27 [kafka.producer.SyncProducer :68-line]-[INFO:] Disconnecting from node2:9092
2016-07-07 09:43:27 [kafka.consumer.ConsumerFetcherThread :68-line]-[INFO:] [ConsumerFetcherThread-test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b-0-3], Starting 
2016-07-07 09:43:27 [kafka.consumer.ConsumerFetcherThread :68-line]-[INFO:] [ConsumerFetcherThread-test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b-0-2], Starting 
2016-07-07 09:43:27 [kafka.consumer.ConsumerFetcherThread :68-line]-[INFO:] [ConsumerFetcherThread-test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b-0-0], Starting 
2016-07-07 09:43:27 [kafka.consumer.ConsumerFetcherThread :68-line]-[INFO:] [ConsumerFetcherThread-test_consumer_group_hctest_huangchao-1467855806803-b6d7af8b-0-1], Starting 
2016-07-07 09:43:27 [kafka.consumer.ConsumerFetcherManager :68-line]-[INFO:] [ConsumerFetcherManager-1467855806936] Added fetcher for partitions ArrayBuffer([[hctest,0], initOffset -1 to broker id:2,host:node3,port:9092] , [[hctest,1], initOffset -1 to broker id:3,host:node4,port:9092] , [[hctest,2], initOffset -1 to broker id:0,host:node1,port:9092] , [[hctest,3], initOffset -1 to broker id:1,host:node2,port:9092] )
2016-07-07 09:43:28 [com.superh.hz.monika.realtime.job.MonitorJobStartup :292-line]-[INFO:] -----------------------------------------
2016-07-07 09:43:28 [com.superh.hz.monika.realtime.job.MonitorJobStartup :293-line]-[INFO:] Time: [1467855808240]ms
2016-07-07 09:43:28 [com.superh.hz.monika.realtime.job.MonitorJobStartup :294-line]-[INFO:] -----------------------------------------
2016-07-07 09:43:28 [com.superh.hz.monika.realtime.job.MonitorJobStartup :301-line]-[INFO:] 当前布控任务总数量：[0]
2016-07-07 09:43:28 [com.superh.hz.monika.realtime.job.MonitorJobStartup :356-line]-[INFO:] -------deal time=>[1467855808288],batch count：[0]
2016-07-07 09:43:28 [com.superh.hz.monika.realtime.job.MonitorJobStartup :357-line]-[INFO:] -------deal time=>[1467855808288],result count：[0]
2016-07-07 09:43:28 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 1 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855804000: hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata/log-1467855588000-1467855648000
2016-07-07 09:43:28 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855804000: 
2016-07-07 09:43:28 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Cleared log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855804000
2016-07-07 09:43:32 [com.superh.hz.monika.realtime.job.MonitorJobStartup :292-line]-[INFO:] -----------------------------------------
2016-07-07 09:43:32 [com.superh.hz.monika.realtime.job.MonitorJobStartup :293-line]-[INFO:] Time: [1467855812013]ms
2016-07-07 09:43:32 [com.superh.hz.monika.realtime.job.MonitorJobStartup :294-line]-[INFO:] -----------------------------------------
2016-07-07 09:43:32 [com.superh.hz.monika.realtime.job.MonitorJobStartup :301-line]-[INFO:] 当前布控任务总数量：[0]
2016-07-07 09:43:32 [com.superh.hz.monika.realtime.job.MonitorJobStartup :356-line]-[INFO:] -------deal time=>[1467855812149],batch count：[3]
2016-07-07 09:43:32 [com.superh.hz.monika.realtime.job.MonitorJobStartup :357-line]-[INFO:] -------deal time=>[1467855812149],result count：[0]
2016-07-07 09:43:32 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855808000: 
2016-07-07 09:43:32 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855808000: 
2016-07-07 09:43:36 [com.superh.hz.monika.realtime.job.MonitorJobStartup :292-line]-[INFO:] -----------------------------------------
2016-07-07 09:43:36 [com.superh.hz.monika.realtime.job.MonitorJobStartup :293-line]-[INFO:] Time: [1467855816000]ms
2016-07-07 09:43:36 [com.superh.hz.monika.realtime.job.MonitorJobStartup :294-line]-[INFO:] -----------------------------------------
2016-07-07 09:43:36 [com.superh.hz.monika.realtime.job.MonitorJobStartup :301-line]-[INFO:] 当前布控任务总数量：[0]
2016-07-07 09:43:36 [com.superh.hz.monika.realtime.job.MonitorJobStartup :356-line]-[INFO:] -------deal time=>[1467855816041],batch count：[0]
2016-07-07 09:43:36 [com.superh.hz.monika.realtime.job.MonitorJobStartup :357-line]-[INFO:] -------deal time=>[1467855816041],result count：[0]
2016-07-07 09:43:36 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855812000: 
2016-07-07 09:43:36 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855812000: 
2016-07-07 09:44:24 [com.superh.hz.monika.realtime.constant.MonikaConfiguration :29-line]-[INFO:] MONITOR_TASK_FLAG is [2]
2016-07-07 09:44:24 [com.superh.hz.monika.realtime.constant.MonikaConfiguration :32-line]-[INFO:] MONIKA_MONITOR_TASK_CLASS is []
2016-07-07 09:44:24 [com.superh.hz.monika.realtime.constant.MonikaConfiguration :35-line]-[INFO:] MONIKA_MONITOR_TASK_PARSER_CLASS is [null]
2016-07-07 09:44:24 [org.apache.hadoop.util.Shell :396-line]-[ERROR:] Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:130)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:94)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:74)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:303)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:790)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:760)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:633)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2160)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2160)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2160)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:874)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:81)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:140)
	at com.superh.hz.monika.realtime.job.MonitorJobStartup.buildReceiveStream(MonitorJobStartup.java:263)
	at com.superh.hz.monika.realtime.job.MonitorJobStartup.main(MonitorJobStartup.java:69)
2016-07-07 09:44:25 [akka.event.slf4j.Slf4jLogger :80-line]-[INFO:] Slf4jLogger started
2016-07-07 09:44:25 [Remoting :74-line]-[INFO:] Starting remoting
2016-07-07 09:44:25 [Remoting :74-line]-[INFO:] Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.16.4.109:55438]
2016-07-07 09:44:25 [org.spark-project.jetty.server.Server :272-line]-[INFO:] jetty-8.y.z-SNAPSHOT
2016-07-07 09:44:25 [org.spark-project.jetty.server.AbstractConnector :338-line]-[INFO:] Started SelectChannelConnector@0.0.0.0:4040
2016-07-07 09:44:27 [ :389-line]-[WARN:] Your hostname, huangchao resolves to a loopback/non-reachable address: fe80:0:0:0:e926:ee9c:e036:a320%eth5, but we couldn't find any external IP address!
2016-07-07 09:44:29 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Recovered 1 write ahead log files from hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata
2016-07-07 09:44:29 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Recovered 1 write ahead log files from hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0
2016-07-07 09:44:29 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Verifying properties
2016-07-07 09:44:29 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property auto.commit.enable is overridden to false
2016-07-07 09:44:29 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property auto.offset.reset is overridden to smallest
2016-07-07 09:44:29 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property group.id is overridden to test_consumer_group_hctest
2016-07-07 09:44:29 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property zookeeper.connect is overridden to node1,node2,node3
2016-07-07 09:44:29 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855869324-2b519d6e], Connecting to zookeeper instance at node1,node2,node3
2016-07-07 09:44:29 [org.I0Itec.zkclient.ZkEventThread :64-line]-[INFO:] Starting ZkClient event thread.
2016-07-07 09:44:29 [org.I0Itec.zkclient.ZkClient :449-line]-[INFO:] zookeeper state changed (SyncConnected)
2016-07-07 09:44:29 [org.I0Itec.zkclient.ZkEventThread :64-line]-[INFO:] Starting ZkClient event thread.
2016-07-07 09:44:29 [org.I0Itec.zkclient.ZkClient :449-line]-[INFO:] zookeeper state changed (SyncConnected)
2016-07-07 09:44:29 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855869324-2b519d6e], begin registering consumer test_consumer_group_hctest_huangchao-1467855869324-2b519d6e in ZK
2016-07-07 09:44:29 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855869324-2b519d6e], end registering consumer test_consumer_group_hctest_huangchao-1467855869324-2b519d6e in ZK
2016-07-07 09:44:29 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855869324-2b519d6e], starting watcher executor thread for consumer test_consumer_group_hctest_huangchao-1467855869324-2b519d6e
2016-07-07 09:44:29 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855869324-2b519d6e], begin rebalancing consumer test_consumer_group_hctest_huangchao-1467855869324-2b519d6e try #0
2016-07-07 09:44:29 [kafka.consumer.ConsumerFetcherManager :68-line]-[INFO:] [ConsumerFetcherManager-1467855869350] Stopping leader finder thread
2016-07-07 09:44:29 [kafka.consumer.ConsumerFetcherManager :68-line]-[INFO:] [ConsumerFetcherManager-1467855869350] Stopping all fetchers
2016-07-07 09:44:29 [kafka.consumer.ConsumerFetcherManager :68-line]-[INFO:] [ConsumerFetcherManager-1467855869350] All connections stopped
2016-07-07 09:44:29 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855869324-2b519d6e], Cleared all relevant queues for this fetcher
2016-07-07 09:44:29 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855869324-2b519d6e], Cleared the data chunks in all the consumer message iterators
2016-07-07 09:44:29 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855869324-2b519d6e], Committing all offsets after clearing the fetcher queues
2016-07-07 09:44:29 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855869324-2b519d6e], Releasing partition ownership
2016-07-07 09:44:29 [kafka.consumer.RangeAssignor :68-line]-[INFO:] Consumer test_consumer_group_hctest_huangchao-1467855869324-2b519d6e rebalancing the following partitions: ArrayBuffer(0, 1, 2, 3) for topic hctest with consumers: List(test_consumer_group_hctest_huangchao-1467855869324-2b519d6e-0)
2016-07-07 09:44:29 [kafka.consumer.RangeAssignor :68-line]-[INFO:] test_consumer_group_hctest_huangchao-1467855869324-2b519d6e-0 attempting to claim partition 0
2016-07-07 09:44:29 [kafka.consumer.RangeAssignor :68-line]-[INFO:] test_consumer_group_hctest_huangchao-1467855869324-2b519d6e-0 attempting to claim partition 1
2016-07-07 09:44:29 [kafka.consumer.RangeAssignor :68-line]-[INFO:] test_consumer_group_hctest_huangchao-1467855869324-2b519d6e-0 attempting to claim partition 2
2016-07-07 09:44:29 [kafka.consumer.RangeAssignor :68-line]-[INFO:] test_consumer_group_hctest_huangchao-1467855869324-2b519d6e-0 attempting to claim partition 3
2016-07-07 09:44:29 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855869324-2b519d6e], test_consumer_group_hctest_huangchao-1467855869324-2b519d6e-0 successfully owned partition 0 for topic hctest
2016-07-07 09:44:29 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855869324-2b519d6e], test_consumer_group_hctest_huangchao-1467855869324-2b519d6e-0 successfully owned partition 1 for topic hctest
2016-07-07 09:44:29 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855869324-2b519d6e], test_consumer_group_hctest_huangchao-1467855869324-2b519d6e-0 successfully owned partition 2 for topic hctest
2016-07-07 09:44:29 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855869324-2b519d6e], test_consumer_group_hctest_huangchao-1467855869324-2b519d6e-0 successfully owned partition 3 for topic hctest
2016-07-07 09:44:29 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855869324-2b519d6e], Consumer test_consumer_group_hctest_huangchao-1467855869324-2b519d6e selected partitions : hctest:0: fetched offset = -1: consumed offset = -1,hctest:1: fetched offset = -1: consumed offset = -1,hctest:2: fetched offset = -1: consumed offset = -1,hctest:3: fetched offset = 2: consumed offset = 2
2016-07-07 09:44:29 [kafka.consumer.ConsumerFetcherManager$LeaderFinderThread :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855869324-2b519d6e-leader-finder-thread], Starting 
2016-07-07 09:44:29 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855869324-2b519d6e], end rebalancing consumer test_consumer_group_hctest_huangchao-1467855869324-2b519d6e try #0
2016-07-07 09:44:29 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Verifying properties
2016-07-07 09:44:29 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property client.id is overridden to test_consumer_group_hctest
2016-07-07 09:44:29 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property metadata.broker.list is overridden to node1:9092,node2:9092,node3:9092,node4:9092
2016-07-07 09:44:29 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property request.timeout.ms is overridden to 30000
2016-07-07 09:44:29 [kafka.client.ClientUtils$ :68-line]-[INFO:] Fetching metadata from broker id:0,host:node1,port:9092 with correlation id 0 for 1 topic(s) Set(hctest)
2016-07-07 09:44:29 [kafka.producer.SyncProducer :68-line]-[INFO:] Connected to node1:9092 for producing
2016-07-07 09:44:29 [kafka.producer.SyncProducer :68-line]-[INFO:] Disconnecting from node1:9092
2016-07-07 09:44:29 [kafka.consumer.ConsumerFetcherThread :68-line]-[INFO:] [ConsumerFetcherThread-test_consumer_group_hctest_huangchao-1467855869324-2b519d6e-0-3], Starting 
2016-07-07 09:44:29 [kafka.consumer.ConsumerFetcherThread :68-line]-[INFO:] [ConsumerFetcherThread-test_consumer_group_hctest_huangchao-1467855869324-2b519d6e-0-2], Starting 
2016-07-07 09:44:29 [kafka.consumer.ConsumerFetcherThread :68-line]-[INFO:] [ConsumerFetcherThread-test_consumer_group_hctest_huangchao-1467855869324-2b519d6e-0-0], Starting 
2016-07-07 09:44:29 [kafka.consumer.ConsumerFetcherThread :68-line]-[INFO:] [ConsumerFetcherThread-test_consumer_group_hctest_huangchao-1467855869324-2b519d6e-0-1], Starting 
2016-07-07 09:44:29 [kafka.consumer.ConsumerFetcherManager :68-line]-[INFO:] [ConsumerFetcherManager-1467855869350] Added fetcher for partitions ArrayBuffer([[hctest,0], initOffset -1 to broker id:2,host:node3,port:9092] , [[hctest,1], initOffset -1 to broker id:3,host:node4,port:9092] , [[hctest,2], initOffset -1 to broker id:0,host:node1,port:9092] , [[hctest,3], initOffset 2 to broker id:1,host:node2,port:9092] )
2016-07-07 09:44:32 [com.superh.hz.monika.realtime.job.MonitorJobStartup :292-line]-[INFO:] -----------------------------------------
2016-07-07 09:44:32 [com.superh.hz.monika.realtime.job.MonitorJobStartup :293-line]-[INFO:] Time: [1467855872078]ms
2016-07-07 09:44:32 [com.superh.hz.monika.realtime.job.MonitorJobStartup :294-line]-[INFO:] -----------------------------------------
2016-07-07 09:44:32 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[1]
2016-07-07 09:44:32 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[4]
2016-07-07 09:44:32 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[5]
2016-07-07 09:44:32 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[6]
2016-07-07 09:44:32 [com.superh.hz.monika.realtime.job.MonitorJobStartup :301-line]-[INFO:] 当前布控任务总数量：[0]
2016-07-07 09:44:32 [com.superh.hz.monika.realtime.job.MonitorJobStartup :356-line]-[INFO:] -------deal time=>[1467855872229],batch count：[1]
2016-07-07 09:44:32 [com.superh.hz.monika.realtime.job.MonitorJobStartup :357-line]-[INFO:] -------deal time=>[1467855872229],result count：[0]
2016-07-07 09:44:32 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855868000: 
2016-07-07 09:44:32 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855868000: 
2016-07-07 09:44:36 [com.superh.hz.monika.realtime.job.MonitorJobStartup :292-line]-[INFO:] -----------------------------------------
2016-07-07 09:44:36 [com.superh.hz.monika.realtime.job.MonitorJobStartup :293-line]-[INFO:] Time: [1467855876000]ms
2016-07-07 09:44:36 [com.superh.hz.monika.realtime.job.MonitorJobStartup :294-line]-[INFO:] -----------------------------------------
2016-07-07 09:44:36 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[1]
2016-07-07 09:44:36 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[4]
2016-07-07 09:44:36 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[5]
2016-07-07 09:44:36 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[6]
2016-07-07 09:44:36 [com.superh.hz.monika.realtime.job.MonitorJobStartup :301-line]-[INFO:] 当前布控任务总数量：[0]
2016-07-07 09:44:36 [com.superh.hz.monika.realtime.job.MonitorJobStartup :356-line]-[INFO:] -------deal time=>[1467855876056],batch count：[0]
2016-07-07 09:44:36 [com.superh.hz.monika.realtime.job.MonitorJobStartup :357-line]-[INFO:] -------deal time=>[1467855876056],result count：[0]
2016-07-07 09:44:36 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 1 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855872000: hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata/log-1467855808036-1467855868036
2016-07-07 09:44:36 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 1 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855872000: hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0/log-1467855808027-1467855868027
2016-07-07 09:44:36 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Cleared log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855872000
2016-07-07 09:44:36 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Cleared log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855872000
2016-07-07 09:44:40 [com.superh.hz.monika.realtime.job.MonitorJobStartup :292-line]-[INFO:] -----------------------------------------
2016-07-07 09:44:40 [com.superh.hz.monika.realtime.job.MonitorJobStartup :293-line]-[INFO:] Time: [1467855880009]ms
2016-07-07 09:44:40 [com.superh.hz.monika.realtime.job.MonitorJobStartup :294-line]-[INFO:] -----------------------------------------
2016-07-07 09:44:40 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[1]
2016-07-07 09:44:40 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[4]
2016-07-07 09:44:40 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[5]
2016-07-07 09:44:40 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[6]
2016-07-07 09:44:40 [com.superh.hz.monika.realtime.job.MonitorJobStartup :301-line]-[INFO:] 当前布控任务总数量：[0]
2016-07-07 09:44:40 [com.superh.hz.monika.realtime.job.MonitorJobStartup :356-line]-[INFO:] -------deal time=>[1467855880060],batch count：[0]
2016-07-07 09:44:40 [com.superh.hz.monika.realtime.job.MonitorJobStartup :357-line]-[INFO:] -------deal time=>[1467855880060],result count：[0]
2016-07-07 09:44:40 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855876000: 
2016-07-07 09:44:40 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855876000: 
2016-07-07 09:44:44 [com.superh.hz.monika.realtime.job.MonitorJobStartup :292-line]-[INFO:] -----------------------------------------
2016-07-07 09:44:44 [com.superh.hz.monika.realtime.job.MonitorJobStartup :293-line]-[INFO:] Time: [1467855884000]ms
2016-07-07 09:44:44 [com.superh.hz.monika.realtime.job.MonitorJobStartup :294-line]-[INFO:] -----------------------------------------
2016-07-07 09:44:44 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[1]
2016-07-07 09:44:44 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[4]
2016-07-07 09:44:44 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[5]
2016-07-07 09:44:44 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[6]
2016-07-07 09:44:44 [com.superh.hz.monika.realtime.job.MonitorJobStartup :301-line]-[INFO:] 当前布控任务总数量：[0]
2016-07-07 09:44:44 [com.superh.hz.monika.realtime.job.MonitorJobStartup :356-line]-[INFO:] -------deal time=>[1467855884047],batch count：[0]
2016-07-07 09:44:44 [com.superh.hz.monika.realtime.job.MonitorJobStartup :357-line]-[INFO:] -------deal time=>[1467855884047],result count：[0]
2016-07-07 09:44:44 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855880000: 
2016-07-07 09:44:44 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855880000: 
2016-07-07 09:44:48 [com.superh.hz.monika.realtime.job.MonitorJobStartup :292-line]-[INFO:] -----------------------------------------
2016-07-07 09:44:48 [com.superh.hz.monika.realtime.job.MonitorJobStartup :293-line]-[INFO:] Time: [1467855888003]ms
2016-07-07 09:44:48 [com.superh.hz.monika.realtime.job.MonitorJobStartup :294-line]-[INFO:] -----------------------------------------
2016-07-07 09:44:48 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[1]
2016-07-07 09:44:48 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[4]
2016-07-07 09:44:48 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[5]
2016-07-07 09:44:48 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[6]
2016-07-07 09:44:48 [com.superh.hz.monika.realtime.job.MonitorJobStartup :301-line]-[INFO:] 当前布控任务总数量：[0]
2016-07-07 09:44:48 [com.superh.hz.monika.realtime.job.MonitorJobStartup :356-line]-[INFO:] -------deal time=>[1467855888032],batch count：[0]
2016-07-07 09:44:48 [com.superh.hz.monika.realtime.job.MonitorJobStartup :357-line]-[INFO:] -------deal time=>[1467855888032],result count：[0]
2016-07-07 09:44:48 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855884000: 
2016-07-07 09:44:48 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855884000: 
2016-07-07 09:45:29 [com.superh.hz.monika.realtime.constant.MonikaConfiguration :29-line]-[INFO:] MONITOR_TASK_FLAG is [1]
2016-07-07 09:45:29 [com.superh.hz.monika.realtime.constant.MonikaConfiguration :32-line]-[INFO:] MONIKA_MONITOR_TASK_CLASS is []
2016-07-07 09:45:29 [com.superh.hz.monika.realtime.constant.MonikaConfiguration :35-line]-[INFO:] MONIKA_MONITOR_TASK_PARSER_CLASS is [null]
2016-07-07 09:45:30 [org.apache.hadoop.util.Shell :396-line]-[ERROR:] Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:130)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:94)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:74)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:303)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:790)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:760)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:633)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2160)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2160)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2160)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:874)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:81)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:140)
	at com.superh.hz.monika.realtime.job.MonitorJobStartup.buildReceiveStream(MonitorJobStartup.java:263)
	at com.superh.hz.monika.realtime.job.MonitorJobStartup.main(MonitorJobStartup.java:69)
2016-07-07 09:45:31 [akka.event.slf4j.Slf4jLogger :80-line]-[INFO:] Slf4jLogger started
2016-07-07 09:45:31 [Remoting :74-line]-[INFO:] Starting remoting
2016-07-07 09:45:31 [Remoting :74-line]-[INFO:] Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.16.4.109:55562]
2016-07-07 09:45:31 [org.spark-project.jetty.server.Server :272-line]-[INFO:] jetty-8.y.z-SNAPSHOT
2016-07-07 09:45:31 [org.spark-project.jetty.server.AbstractConnector :338-line]-[INFO:] Started SelectChannelConnector@0.0.0.0:4040
2016-07-07 09:45:33 [ :389-line]-[WARN:] Your hostname, huangchao resolves to a loopback/non-reachable address: fe80:0:0:0:e926:ee9c:e036:a320%eth5, but we couldn't find any external IP address!
2016-07-07 09:45:34 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Recovered 1 write ahead log files from hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata
2016-07-07 09:45:34 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Recovered 1 write ahead log files from hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0
2016-07-07 09:45:34 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Verifying properties
2016-07-07 09:45:34 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property auto.commit.enable is overridden to false
2016-07-07 09:45:34 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property auto.offset.reset is overridden to smallest
2016-07-07 09:45:34 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property group.id is overridden to test_consumer_group_hctest
2016-07-07 09:45:34 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property zookeeper.connect is overridden to node1,node2,node3
2016-07-07 09:45:34 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855934904-949eabd5], Connecting to zookeeper instance at node1,node2,node3
2016-07-07 09:45:34 [org.I0Itec.zkclient.ZkEventThread :64-line]-[INFO:] Starting ZkClient event thread.
2016-07-07 09:45:34 [org.I0Itec.zkclient.ZkClient :449-line]-[INFO:] zookeeper state changed (SyncConnected)
2016-07-07 09:45:34 [org.I0Itec.zkclient.ZkEventThread :64-line]-[INFO:] Starting ZkClient event thread.
2016-07-07 09:45:34 [org.I0Itec.zkclient.ZkClient :449-line]-[INFO:] zookeeper state changed (SyncConnected)
2016-07-07 09:45:34 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855934904-949eabd5], begin registering consumer test_consumer_group_hctest_huangchao-1467855934904-949eabd5 in ZK
2016-07-07 09:45:34 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855934904-949eabd5], end registering consumer test_consumer_group_hctest_huangchao-1467855934904-949eabd5 in ZK
2016-07-07 09:45:34 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855934904-949eabd5], starting watcher executor thread for consumer test_consumer_group_hctest_huangchao-1467855934904-949eabd5
2016-07-07 09:45:34 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855934904-949eabd5], begin rebalancing consumer test_consumer_group_hctest_huangchao-1467855934904-949eabd5 try #0
2016-07-07 09:45:35 [kafka.consumer.ConsumerFetcherManager :68-line]-[INFO:] [ConsumerFetcherManager-1467855934931] Stopping leader finder thread
2016-07-07 09:45:35 [kafka.consumer.ConsumerFetcherManager :68-line]-[INFO:] [ConsumerFetcherManager-1467855934931] Stopping all fetchers
2016-07-07 09:45:35 [kafka.consumer.ConsumerFetcherManager :68-line]-[INFO:] [ConsumerFetcherManager-1467855934931] All connections stopped
2016-07-07 09:45:35 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855934904-949eabd5], Cleared all relevant queues for this fetcher
2016-07-07 09:45:35 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855934904-949eabd5], Cleared the data chunks in all the consumer message iterators
2016-07-07 09:45:35 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855934904-949eabd5], Committing all offsets after clearing the fetcher queues
2016-07-07 09:45:35 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855934904-949eabd5], Releasing partition ownership
2016-07-07 09:45:35 [kafka.consumer.RangeAssignor :68-line]-[INFO:] Consumer test_consumer_group_hctest_huangchao-1467855934904-949eabd5 rebalancing the following partitions: ArrayBuffer(0, 1, 2, 3) for topic hctest with consumers: List(test_consumer_group_hctest_huangchao-1467855934904-949eabd5-0)
2016-07-07 09:45:35 [kafka.consumer.RangeAssignor :68-line]-[INFO:] test_consumer_group_hctest_huangchao-1467855934904-949eabd5-0 attempting to claim partition 0
2016-07-07 09:45:35 [kafka.consumer.RangeAssignor :68-line]-[INFO:] test_consumer_group_hctest_huangchao-1467855934904-949eabd5-0 attempting to claim partition 1
2016-07-07 09:45:35 [kafka.consumer.RangeAssignor :68-line]-[INFO:] test_consumer_group_hctest_huangchao-1467855934904-949eabd5-0 attempting to claim partition 2
2016-07-07 09:45:35 [kafka.consumer.RangeAssignor :68-line]-[INFO:] test_consumer_group_hctest_huangchao-1467855934904-949eabd5-0 attempting to claim partition 3
2016-07-07 09:45:35 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855934904-949eabd5], test_consumer_group_hctest_huangchao-1467855934904-949eabd5-0 successfully owned partition 0 for topic hctest
2016-07-07 09:45:35 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855934904-949eabd5], test_consumer_group_hctest_huangchao-1467855934904-949eabd5-0 successfully owned partition 1 for topic hctest
2016-07-07 09:45:35 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855934904-949eabd5], test_consumer_group_hctest_huangchao-1467855934904-949eabd5-0 successfully owned partition 2 for topic hctest
2016-07-07 09:45:35 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855934904-949eabd5], test_consumer_group_hctest_huangchao-1467855934904-949eabd5-0 successfully owned partition 3 for topic hctest
2016-07-07 09:45:35 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855934904-949eabd5], Consumer test_consumer_group_hctest_huangchao-1467855934904-949eabd5 selected partitions : hctest:0: fetched offset = -1: consumed offset = -1,hctest:1: fetched offset = -1: consumed offset = -1,hctest:2: fetched offset = -1: consumed offset = -1,hctest:3: fetched offset = 2: consumed offset = 2
2016-07-07 09:45:35 [kafka.consumer.ConsumerFetcherManager$LeaderFinderThread :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855934904-949eabd5-leader-finder-thread], Starting 
2016-07-07 09:45:35 [kafka.consumer.ZookeeperConsumerConnector :68-line]-[INFO:] [test_consumer_group_hctest_huangchao-1467855934904-949eabd5], end rebalancing consumer test_consumer_group_hctest_huangchao-1467855934904-949eabd5 try #0
2016-07-07 09:45:35 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Verifying properties
2016-07-07 09:45:35 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property client.id is overridden to test_consumer_group_hctest
2016-07-07 09:45:35 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property metadata.broker.list is overridden to node1:9092,node2:9092,node3:9092,node4:9092
2016-07-07 09:45:35 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property request.timeout.ms is overridden to 30000
2016-07-07 09:45:35 [kafka.client.ClientUtils$ :68-line]-[INFO:] Fetching metadata from broker id:1,host:node2,port:9092 with correlation id 0 for 1 topic(s) Set(hctest)
2016-07-07 09:45:35 [kafka.producer.SyncProducer :68-line]-[INFO:] Connected to node2:9092 for producing
2016-07-07 09:45:35 [kafka.producer.SyncProducer :68-line]-[INFO:] Disconnecting from node2:9092
2016-07-07 09:45:35 [kafka.consumer.ConsumerFetcherThread :68-line]-[INFO:] [ConsumerFetcherThread-test_consumer_group_hctest_huangchao-1467855934904-949eabd5-0-3], Starting 
2016-07-07 09:45:35 [kafka.consumer.ConsumerFetcherThread :68-line]-[INFO:] [ConsumerFetcherThread-test_consumer_group_hctest_huangchao-1467855934904-949eabd5-0-2], Starting 
2016-07-07 09:45:35 [kafka.consumer.ConsumerFetcherThread :68-line]-[INFO:] [ConsumerFetcherThread-test_consumer_group_hctest_huangchao-1467855934904-949eabd5-0-0], Starting 
2016-07-07 09:45:35 [kafka.consumer.ConsumerFetcherThread :68-line]-[INFO:] [ConsumerFetcherThread-test_consumer_group_hctest_huangchao-1467855934904-949eabd5-0-1], Starting 
2016-07-07 09:45:35 [kafka.consumer.ConsumerFetcherManager :68-line]-[INFO:] [ConsumerFetcherManager-1467855934931] Added fetcher for partitions ArrayBuffer([[hctest,0], initOffset -1 to broker id:2,host:node3,port:9092] , [[hctest,1], initOffset -1 to broker id:3,host:node4,port:9092] , [[hctest,2], initOffset -1 to broker id:0,host:node1,port:9092] , [[hctest,3], initOffset 2 to broker id:1,host:node2,port:9092] )
2016-07-07 09:45:36 [com.superh.hz.monika.realtime.job.MonitorJobStartup :292-line]-[INFO:] -----------------------------------------
2016-07-07 09:45:36 [com.superh.hz.monika.realtime.job.MonitorJobStartup :293-line]-[INFO:] Time: [1467855936188]ms
2016-07-07 09:45:36 [com.superh.hz.monika.realtime.job.MonitorJobStartup :294-line]-[INFO:] -----------------------------------------
2016-07-07 09:45:36 [com.superh.hz.monika.realtime.task.SimpleMonitorTaskParser :29-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[6]
2016-07-07 09:45:36 [com.superh.hz.monika.realtime.job.MonitorJobStartup :301-line]-[INFO:] 当前布控任务总数量：[3]
2016-07-07 09:45:36 [com.superh.hz.monika.realtime.job.MonitorJobStartup :356-line]-[INFO:] -------deal time=>[1467855936279],batch count：[0]
2016-07-07 09:45:36 [com.superh.hz.monika.realtime.job.MonitorJobStartup :357-line]-[INFO:] -------deal time=>[1467855936279],result count：[0]
2016-07-07 09:45:36 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 1 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855932000: hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata/log-1467855870169-1467855930169
2016-07-07 09:45:36 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Cleared log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855932000
2016-07-07 09:45:36 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 1 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855932000: hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0/log-1467855870008-1467855930008
2016-07-07 09:45:36 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Cleared log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855932000
2016-07-07 09:45:40 [com.superh.hz.monika.realtime.job.MonitorJobStartup :292-line]-[INFO:] -----------------------------------------
2016-07-07 09:45:40 [com.superh.hz.monika.realtime.job.MonitorJobStartup :293-line]-[INFO:] Time: [1467855940013]ms
2016-07-07 09:45:40 [com.superh.hz.monika.realtime.job.MonitorJobStartup :294-line]-[INFO:] -----------------------------------------
2016-07-07 09:45:40 [com.superh.hz.monika.realtime.task.SimpleMonitorTaskParser :29-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[6]
2016-07-07 09:45:40 [com.superh.hz.monika.realtime.job.MonitorJobStartup :301-line]-[INFO:] 当前布控任务总数量：[3]
2016-07-07 09:45:40 [com.superh.hz.monika.realtime.job.MonitorJobStartup :356-line]-[INFO:] -------deal time=>[1467855940121],batch count：[1]
2016-07-07 09:45:40 [com.superh.hz.monika.realtime.job.MonitorJobStartup :357-line]-[INFO:] -------deal time=>[1467855940121],result count：[2]
2016-07-07 09:45:40 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855936000: 
2016-07-07 09:45:40 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855936000: 
2016-07-07 09:45:44 [com.superh.hz.monika.realtime.job.MonitorJobStartup :292-line]-[INFO:] -----------------------------------------
2016-07-07 09:45:44 [com.superh.hz.monika.realtime.job.MonitorJobStartup :293-line]-[INFO:] Time: [1467855944000]ms
2016-07-07 09:45:44 [com.superh.hz.monika.realtime.job.MonitorJobStartup :294-line]-[INFO:] -----------------------------------------
2016-07-07 09:45:44 [com.superh.hz.monika.realtime.task.SimpleMonitorTaskParser :29-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[6]
2016-07-07 09:45:44 [com.superh.hz.monika.realtime.job.MonitorJobStartup :301-line]-[INFO:] 当前布控任务总数量：[3]
2016-07-07 09:45:44 [com.superh.hz.monika.realtime.job.MonitorJobStartup :356-line]-[INFO:] -------deal time=>[1467855944057],batch count：[0]
2016-07-07 09:45:44 [com.superh.hz.monika.realtime.job.MonitorJobStartup :357-line]-[INFO:] -------deal time=>[1467855944057],result count：[0]
2016-07-07 09:45:44 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855940000: 
2016-07-07 09:45:44 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855940000: 
2016-07-07 09:45:48 [com.superh.hz.monika.realtime.job.MonitorJobStartup :292-line]-[INFO:] -----------------------------------------
2016-07-07 09:45:48 [com.superh.hz.monika.realtime.job.MonitorJobStartup :293-line]-[INFO:] Time: [1467855948007]ms
2016-07-07 09:45:48 [com.superh.hz.monika.realtime.job.MonitorJobStartup :294-line]-[INFO:] -----------------------------------------
2016-07-07 09:45:48 [com.superh.hz.monika.realtime.task.SimpleMonitorTaskParser :29-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[6]
2016-07-07 09:45:48 [com.superh.hz.monika.realtime.job.MonitorJobStartup :301-line]-[INFO:] 当前布控任务总数量：[3]
2016-07-07 09:45:48 [com.superh.hz.monika.realtime.job.MonitorJobStartup :356-line]-[INFO:] -------deal time=>[1467855948048],batch count：[0]
2016-07-07 09:45:48 [com.superh.hz.monika.realtime.job.MonitorJobStartup :357-line]-[INFO:] -------deal time=>[1467855948048],result count：[0]
2016-07-07 09:45:48 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855944000: 
2016-07-07 09:45:48 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855944000: 
2016-07-07 09:45:52 [com.superh.hz.monika.realtime.job.MonitorJobStartup :292-line]-[INFO:] -----------------------------------------
2016-07-07 09:45:52 [com.superh.hz.monika.realtime.job.MonitorJobStartup :293-line]-[INFO:] Time: [1467855952007]ms
2016-07-07 09:45:52 [com.superh.hz.monika.realtime.job.MonitorJobStartup :294-line]-[INFO:] -----------------------------------------
2016-07-07 09:45:52 [com.superh.hz.monika.realtime.task.SimpleMonitorTaskParser :29-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[6]
2016-07-07 09:45:52 [com.superh.hz.monika.realtime.job.MonitorJobStartup :301-line]-[INFO:] 当前布控任务总数量：[3]
2016-07-07 09:45:52 [com.superh.hz.monika.realtime.job.MonitorJobStartup :356-line]-[INFO:] -------deal time=>[1467855952058],batch count：[0]
2016-07-07 09:45:52 [com.superh.hz.monika.realtime.job.MonitorJobStartup :357-line]-[INFO:] -------deal time=>[1467855952058],result count：[0]
2016-07-07 09:45:52 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855948000: 
2016-07-07 09:45:52 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855948000: 
2016-07-07 09:45:56 [com.superh.hz.monika.realtime.job.MonitorJobStartup :292-line]-[INFO:] -----------------------------------------
2016-07-07 09:45:56 [com.superh.hz.monika.realtime.job.MonitorJobStartup :293-line]-[INFO:] Time: [1467855956006]ms
2016-07-07 09:45:56 [com.superh.hz.monika.realtime.job.MonitorJobStartup :294-line]-[INFO:] -----------------------------------------
2016-07-07 09:45:56 [com.superh.hz.monika.realtime.task.SimpleMonitorTaskParser :29-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[6]
2016-07-07 09:45:56 [com.superh.hz.monika.realtime.job.MonitorJobStartup :301-line]-[INFO:] 当前布控任务总数量：[3]
2016-07-07 09:45:56 [com.superh.hz.monika.realtime.job.MonitorJobStartup :356-line]-[INFO:] -------deal time=>[1467855956044],batch count：[0]
2016-07-07 09:45:56 [com.superh.hz.monika.realtime.job.MonitorJobStartup :357-line]-[INFO:] -------deal time=>[1467855956044],result count：[0]
2016-07-07 09:45:56 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855952000: 
2016-07-07 09:45:56 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855952000: 
2016-07-07 09:46:00 [com.superh.hz.monika.realtime.job.MonitorJobStartup :292-line]-[INFO:] -----------------------------------------
2016-07-07 09:46:00 [com.superh.hz.monika.realtime.job.MonitorJobStartup :293-line]-[INFO:] Time: [1467855960008]ms
2016-07-07 09:46:00 [com.superh.hz.monika.realtime.job.MonitorJobStartup :294-line]-[INFO:] -----------------------------------------
2016-07-07 09:46:00 [com.superh.hz.monika.realtime.task.SimpleMonitorTaskParser :29-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[6]
2016-07-07 09:46:00 [com.superh.hz.monika.realtime.job.MonitorJobStartup :301-line]-[INFO:] 当前布控任务总数量：[3]
2016-07-07 09:46:00 [com.superh.hz.monika.realtime.job.MonitorJobStartup :356-line]-[INFO:] -------deal time=>[1467855960048],batch count：[0]
2016-07-07 09:46:00 [com.superh.hz.monika.realtime.job.MonitorJobStartup :357-line]-[INFO:] -------deal time=>[1467855960048],result count：[0]
2016-07-07 09:46:00 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855956000: 
2016-07-07 09:46:00 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855956000: 
2016-07-07 09:46:04 [com.superh.hz.monika.realtime.job.MonitorJobStartup :292-line]-[INFO:] -----------------------------------------
2016-07-07 09:46:04 [com.superh.hz.monika.realtime.job.MonitorJobStartup :293-line]-[INFO:] Time: [1467855964004]ms
2016-07-07 09:46:04 [com.superh.hz.monika.realtime.job.MonitorJobStartup :294-line]-[INFO:] -----------------------------------------
2016-07-07 09:46:04 [com.superh.hz.monika.realtime.task.SimpleMonitorTaskParser :29-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[6]
2016-07-07 09:46:04 [com.superh.hz.monika.realtime.job.MonitorJobStartup :301-line]-[INFO:] 当前布控任务总数量：[3]
2016-07-07 09:46:04 [com.superh.hz.monika.realtime.job.MonitorJobStartup :356-line]-[INFO:] -------deal time=>[1467855964015],batch count：[0]
2016-07-07 09:46:04 [com.superh.hz.monika.realtime.job.MonitorJobStartup :357-line]-[INFO:] -------deal time=>[1467855964015],result count：[0]
2016-07-07 09:46:04 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855960000: 
2016-07-07 09:46:04 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855960000: 
2016-07-07 09:46:08 [com.superh.hz.monika.realtime.job.MonitorJobStartup :292-line]-[INFO:] -----------------------------------------
2016-07-07 09:46:08 [com.superh.hz.monika.realtime.job.MonitorJobStartup :293-line]-[INFO:] Time: [1467855968000]ms
2016-07-07 09:46:08 [com.superh.hz.monika.realtime.job.MonitorJobStartup :294-line]-[INFO:] -----------------------------------------
2016-07-07 09:46:08 [com.superh.hz.monika.realtime.task.SimpleMonitorTaskParser :29-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[6]
2016-07-07 09:46:08 [com.superh.hz.monika.realtime.job.MonitorJobStartup :301-line]-[INFO:] 当前布控任务总数量：[3]
2016-07-07 09:46:08 [com.superh.hz.monika.realtime.job.MonitorJobStartup :356-line]-[INFO:] -------deal time=>[1467855968005],batch count：[0]
2016-07-07 09:46:08 [com.superh.hz.monika.realtime.job.MonitorJobStartup :357-line]-[INFO:] -------deal time=>[1467855968005],result count：[0]
2016-07-07 09:46:08 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855964000: 
2016-07-07 09:46:08 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855964000: 
2016-07-07 09:46:12 [com.superh.hz.monika.realtime.job.MonitorJobStartup :292-line]-[INFO:] -----------------------------------------
2016-07-07 09:46:12 [com.superh.hz.monika.realtime.job.MonitorJobStartup :293-line]-[INFO:] Time: [1467855972003]ms
2016-07-07 09:46:12 [com.superh.hz.monika.realtime.job.MonitorJobStartup :294-line]-[INFO:] -----------------------------------------
2016-07-07 09:46:12 [com.superh.hz.monika.realtime.task.SimpleMonitorTaskParser :29-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[6]
2016-07-07 09:46:12 [com.superh.hz.monika.realtime.job.MonitorJobStartup :301-line]-[INFO:] 当前布控任务总数量：[3]
2016-07-07 09:46:12 [com.superh.hz.monika.realtime.job.MonitorJobStartup :356-line]-[INFO:] -------deal time=>[1467855972016],batch count：[0]
2016-07-07 09:46:12 [com.superh.hz.monika.realtime.job.MonitorJobStartup :357-line]-[INFO:] -------deal time=>[1467855972016],result count：[0]
2016-07-07 09:46:12 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855968000: 
2016-07-07 09:46:12 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855968000: 
2016-07-07 09:46:16 [com.superh.hz.monika.realtime.job.MonitorJobStartup :292-line]-[INFO:] -----------------------------------------
2016-07-07 09:46:16 [com.superh.hz.monika.realtime.job.MonitorJobStartup :293-line]-[INFO:] Time: [1467855976006]ms
2016-07-07 09:46:16 [com.superh.hz.monika.realtime.job.MonitorJobStartup :294-line]-[INFO:] -----------------------------------------
2016-07-07 09:46:16 [com.superh.hz.monika.realtime.task.SimpleMonitorTaskParser :29-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[6]
2016-07-07 09:46:16 [com.superh.hz.monika.realtime.job.MonitorJobStartup :301-line]-[INFO:] 当前布控任务总数量：[3]
2016-07-07 09:46:16 [com.superh.hz.monika.realtime.job.MonitorJobStartup :356-line]-[INFO:] -------deal time=>[1467855976032],batch count：[0]
2016-07-07 09:46:16 [com.superh.hz.monika.realtime.job.MonitorJobStartup :357-line]-[INFO:] -------deal time=>[1467855976032],result count：[0]
2016-07-07 09:46:16 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855972000: 
2016-07-07 09:46:16 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855972000: 
2016-07-07 09:46:20 [com.superh.hz.monika.realtime.job.MonitorJobStartup :292-line]-[INFO:] -----------------------------------------
2016-07-07 09:46:20 [com.superh.hz.monika.realtime.job.MonitorJobStartup :293-line]-[INFO:] Time: [1467855980000]ms
2016-07-07 09:46:20 [com.superh.hz.monika.realtime.job.MonitorJobStartup :294-line]-[INFO:] -----------------------------------------
2016-07-07 09:46:20 [com.superh.hz.monika.realtime.task.SimpleMonitorTaskParser :29-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[6]
2016-07-07 09:46:20 [com.superh.hz.monika.realtime.job.MonitorJobStartup :301-line]-[INFO:] 当前布控任务总数量：[3]
2016-07-07 09:46:20 [com.superh.hz.monika.realtime.job.MonitorJobStartup :356-line]-[INFO:] -------deal time=>[1467855980023],batch count：[0]
2016-07-07 09:46:20 [com.superh.hz.monika.realtime.job.MonitorJobStartup :357-line]-[INFO:] -------deal time=>[1467855980023],result count：[0]
2016-07-07 09:46:20 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855976000: 
2016-07-07 09:46:20 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855976000: 
2016-07-07 09:46:24 [com.superh.hz.monika.realtime.job.MonitorJobStartup :292-line]-[INFO:] -----------------------------------------
2016-07-07 09:46:24 [com.superh.hz.monika.realtime.job.MonitorJobStartup :293-line]-[INFO:] Time: [1467855984006]ms
2016-07-07 09:46:24 [com.superh.hz.monika.realtime.job.MonitorJobStartup :294-line]-[INFO:] -----------------------------------------
2016-07-07 09:46:24 [com.superh.hz.monika.realtime.task.SimpleMonitorTaskParser :29-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[6]
2016-07-07 09:46:24 [com.superh.hz.monika.realtime.job.MonitorJobStartup :301-line]-[INFO:] 当前布控任务总数量：[3]
2016-07-07 09:46:24 [com.superh.hz.monika.realtime.job.MonitorJobStartup :356-line]-[INFO:] -------deal time=>[1467855984043],batch count：[0]
2016-07-07 09:46:24 [com.superh.hz.monika.realtime.job.MonitorJobStartup :357-line]-[INFO:] -------deal time=>[1467855984043],result count：[0]
2016-07-07 09:46:24 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedBlockMetadata older than 1467855980000: 
2016-07-07 09:46:24 [WriteAheadLogManager  for Thread :58-line]-[INFO:] Attempting to clear 0 old log files in hdfs://mycluster/user/hadoop/hc/checkpoint2/receivedData/0 older than 1467855980000: 
2016-07-07 09:49:52 [com.superh.hz.monika.realtime.constant.MonikaConfiguration :29-line]-[INFO:] MONITOR_TASK_FLAG is [2]
2016-07-07 09:49:52 [com.superh.hz.monika.realtime.constant.MonikaConfiguration :32-line]-[INFO:] MONIKA_MONITOR_TASK_CLASS is []
2016-07-07 09:49:52 [com.superh.hz.monika.realtime.constant.MonikaConfiguration :35-line]-[INFO:] MONIKA_MONITOR_TASK_PARSER_CLASS is [null]
2016-07-07 09:49:52 [org.apache.hadoop.util.Shell :396-line]-[ERROR:] Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:130)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:94)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:74)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:303)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:790)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:760)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:633)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2160)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2160)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2160)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:874)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:81)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:140)
	at com.superh.hz.monika.realtime.job.MonitorJobStartup.buildDirectStream(MonitorJobStartup.java:86)
	at com.superh.hz.monika.realtime.job.MonitorJobStartup.main(MonitorJobStartup.java:67)
2016-07-07 09:49:53 [akka.event.slf4j.Slf4jLogger :80-line]-[INFO:] Slf4jLogger started
2016-07-07 09:49:53 [Remoting :74-line]-[INFO:] Starting remoting
2016-07-07 09:49:53 [Remoting :74-line]-[INFO:] Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.16.4.109:55765]
2016-07-07 09:49:53 [org.spark-project.jetty.server.Server :272-line]-[INFO:] jetty-8.y.z-SNAPSHOT
2016-07-07 09:49:53 [org.spark-project.jetty.server.AbstractConnector :338-line]-[INFO:] Started SelectChannelConnector@0.0.0.0:4040
2016-07-07 09:49:56 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Verifying properties
2016-07-07 09:49:56 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property group.id is overridden to 
2016-07-07 09:49:56 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property zookeeper.connect is overridden to 
2016-07-07 09:49:56 [com.superh.hz.monika.realtime.job.MonitorJobStartup :148-line]-[INFO:] -----------------------------------------
2016-07-07 09:49:56 [com.superh.hz.monika.realtime.job.MonitorJobStartup :149-line]-[INFO:] Time: [1467856196107]ms
2016-07-07 09:49:56 [com.superh.hz.monika.realtime.job.MonitorJobStartup :151-line]-[INFO:] topic:[hctest], partition:[3], fromOffset:[0], toOffset:[3]
2016-07-07 09:49:56 [com.superh.hz.monika.realtime.job.MonitorJobStartup :151-line]-[INFO:] topic:[hctest], partition:[2], fromOffset:[0], toOffset:[0]
2016-07-07 09:49:56 [com.superh.hz.monika.realtime.job.MonitorJobStartup :151-line]-[INFO:] topic:[hctest], partition:[1], fromOffset:[0], toOffset:[0]
2016-07-07 09:49:56 [com.superh.hz.monika.realtime.job.MonitorJobStartup :151-line]-[INFO:] topic:[hctest], partition:[0], fromOffset:[0], toOffset:[0]
2016-07-07 09:49:56 [com.superh.hz.monika.realtime.job.MonitorJobStartup :158-line]-[INFO:] update kafka offset completed,topic:meta.
2016-07-07 09:49:56 [com.superh.hz.monika.realtime.job.MonitorJobStartup :159-line]-[INFO:] -----------------------------------------
2016-07-07 09:49:56 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[1]
2016-07-07 09:49:56 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[4]
2016-07-07 09:49:56 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[5]
2016-07-07 09:49:56 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[6]
2016-07-07 09:49:56 [com.superh.hz.monika.realtime.job.MonitorJobStartup :164-line]-[INFO:] ----------------当前布控任务总数量：[0]
2016-07-07 09:49:56 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Verifying properties
2016-07-07 09:49:56 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property group.id is overridden to 
2016-07-07 09:49:56 [kafka.utils.VerifiableProperties :68-line]-[INFO:] Property zookeeper.connect is overridden to 
2016-07-07 09:49:56 [com.superh.hz.monika.realtime.job.MonitorJobStartup :220-line]-[INFO:] ----------------deal time=>[1467856196393],batch count：[3]
2016-07-07 09:49:56 [com.superh.hz.monika.realtime.job.MonitorJobStartup :221-line]-[INFO:] ----------------deal time=>[1467856196393],result count：[0]
2016-07-07 09:50:00 [com.superh.hz.monika.realtime.job.MonitorJobStartup :148-line]-[INFO:] -----------------------------------------
2016-07-07 09:50:00 [com.superh.hz.monika.realtime.job.MonitorJobStartup :149-line]-[INFO:] Time: [1467856200016]ms
2016-07-07 09:50:00 [com.superh.hz.monika.realtime.job.MonitorJobStartup :151-line]-[INFO:] topic:[hctest], partition:[0], fromOffset:[0], toOffset:[0]
2016-07-07 09:50:00 [com.superh.hz.monika.realtime.job.MonitorJobStartup :151-line]-[INFO:] topic:[hctest], partition:[3], fromOffset:[3], toOffset:[3]
2016-07-07 09:50:00 [com.superh.hz.monika.realtime.job.MonitorJobStartup :151-line]-[INFO:] topic:[hctest], partition:[1], fromOffset:[0], toOffset:[0]
2016-07-07 09:50:00 [com.superh.hz.monika.realtime.job.MonitorJobStartup :151-line]-[INFO:] topic:[hctest], partition:[2], fromOffset:[0], toOffset:[0]
2016-07-07 09:50:00 [com.superh.hz.monika.realtime.job.MonitorJobStartup :158-line]-[INFO:] update kafka offset completed,topic:meta.
2016-07-07 09:50:00 [com.superh.hz.monika.realtime.job.MonitorJobStartup :159-line]-[INFO:] -----------------------------------------
2016-07-07 09:50:00 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[1]
2016-07-07 09:50:00 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[4]
2016-07-07 09:50:00 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[5]
2016-07-07 09:50:00 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[6]
2016-07-07 09:50:00 [com.superh.hz.monika.realtime.job.MonitorJobStartup :164-line]-[INFO:] ----------------当前布控任务总数量：[0]
2016-07-07 09:50:00 [com.superh.hz.monika.realtime.job.MonitorJobStartup :220-line]-[INFO:] ----------------deal time=>[1467856200072],batch count：[0]
2016-07-07 09:50:00 [com.superh.hz.monika.realtime.job.MonitorJobStartup :221-line]-[INFO:] ----------------deal time=>[1467856200072],result count：[0]
2016-07-07 09:50:04 [com.superh.hz.monika.realtime.job.MonitorJobStartup :148-line]-[INFO:] -----------------------------------------
2016-07-07 09:50:04 [com.superh.hz.monika.realtime.job.MonitorJobStartup :149-line]-[INFO:] Time: [1467856204026]ms
2016-07-07 09:50:04 [com.superh.hz.monika.realtime.job.MonitorJobStartup :151-line]-[INFO:] topic:[hctest], partition:[0], fromOffset:[0], toOffset:[0]
2016-07-07 09:50:04 [com.superh.hz.monika.realtime.job.MonitorJobStartup :151-line]-[INFO:] topic:[hctest], partition:[3], fromOffset:[3], toOffset:[3]
2016-07-07 09:50:04 [com.superh.hz.monika.realtime.job.MonitorJobStartup :151-line]-[INFO:] topic:[hctest], partition:[1], fromOffset:[0], toOffset:[0]
2016-07-07 09:50:04 [com.superh.hz.monika.realtime.job.MonitorJobStartup :151-line]-[INFO:] topic:[hctest], partition:[2], fromOffset:[0], toOffset:[0]
2016-07-07 09:50:04 [com.superh.hz.monika.realtime.job.MonitorJobStartup :158-line]-[INFO:] update kafka offset completed,topic:meta.
2016-07-07 09:50:04 [com.superh.hz.monika.realtime.job.MonitorJobStartup :159-line]-[INFO:] -----------------------------------------
2016-07-07 09:50:04 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[1]
2016-07-07 09:50:04 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[4]
2016-07-07 09:50:04 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[5]
2016-07-07 09:50:04 [com.superh.hz.monika.realtime.task.CommonMonitorTaskParser :31-line]-[ERROR:] task param string is null or not format-task type is[1],task id is[6]
2016-07-07 09:50:04 [com.superh.hz.monika.realtime.job.MonitorJobStartup :164-line]-[INFO:] ----------------当前布控任务总数量：[0]
2016-07-07 09:50:04 [com.superh.hz.monika.realtime.job.MonitorJobStartup :220-line]-[INFO:] ----------------deal time=>[1467856204076],batch count：[0]
2016-07-07 09:50:04 [com.superh.hz.monika.realtime.job.MonitorJobStartup :221-line]-[INFO:] ----------------deal time=>[1467856204076],result count：[0]
